{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NZ6TXg8HqDtX"
   },
   "source": [
    "# Importing And Installing Necessary Libaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3254,
     "status": "ok",
     "timestamp": 1653290698902,
     "user": {
      "displayName": "Yunya Gao",
      "userId": "05443726764578958815"
     },
     "user_tz": -120
    },
    "id": "FjiHeKoQqDta",
    "outputId": "8cd168d5-205a-4f50-93af-76be7ced76af"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "from tensorflow  import keras\n",
    "\n",
    "#Download Model: pre-programmed model from github\n",
    "import segmentation_models as sm \n",
    "from segmentation_models import Unet\n",
    "from segmentation_models import get_preprocessing\n",
    "from keras import metrics\n",
    "from keras.models import load_model\n",
    "\n",
    "#Import other libaries necessary for preparing and analyzing the data\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from PIL import Image, ImageEnhance\n",
    "import rasterio\n",
    "import numpy as np\n",
    "import patchify\n",
    "from patchify import unpatchify \n",
    "from sklearn.model_selection import train_test_split\n",
    "import math\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "# save model results\n",
    "from io import BytesIO\n",
    "from keras.utils  import img_to_array\n",
    "from keras.utils  import array_to_img\n",
    "from keras.utils import save_img\n",
    "\n",
    "# Configure TensorFlow environment\n",
    "tf.compat.v1.enable_eager_execution()\n",
    "TF_ENABLE_ONEDNN_OPTS=0\n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'TRUE'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yjlc2iYuqDtc"
   },
   "source": [
    "# Import and Prepare Training Data \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the patch size and steps of the training image\n",
    "ps=64 # patchsize\n",
    "s=int(ps/4) #steps\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Training Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1450,
     "status": "ok",
     "timestamp": 1653290705016,
     "user": {
      "displayName": "Yunya Gao",
      "userId": "05443726764578958815"
     },
     "user_tz": -120
    },
    "id": "vpsWxucDqDtd",
    "outputId": "667344a6-35a9-4539-fe98-2783a6c93ae3"
   },
   "outputs": [],
   "source": [
    "img_path=\"Image_Training.tif\"# Path to Image\n",
    "\n",
    "# read geotiff data to numpy array\n",
    "\n",
    "with rasterio.open(img_path, 'r') as ds:\n",
    "\n",
    "    arr = ds.read() \n",
    "    \n",
    "\n",
    "    \n",
    "# change the shape of input tiff for feeding models\n",
    "\n",
    "arr1 = np.swapaxes(arr, 1, 0)\n",
    "\n",
    "arr2_image = np.swapaxes(arr1, 1, 2)\n",
    "\n",
    "print(arr2_image.shape) \n",
    "\n",
    "\n",
    "# create smaller image patches for training\n",
    "\n",
    "patch2 = patchify.patchify(arr2_image ,(ps,ps,3), step=s)\n",
    "print (patch2.shape)\n",
    "\n",
    "# Out of the image patches we create a tensor: number of sample images; size; number of channels \n",
    "\n",
    "patch_X = np.reshape(patch2, (patch2.shape[0]*patch2.shape[1],ps,ps,3)) \n",
    "\n",
    "print(patch_X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 366,
     "status": "ok",
     "timestamp": 1653290707972,
     "user": {
      "displayName": "Yunya Gao",
      "userId": "05443726764578958815"
     },
     "user_tz": -120
    },
    "id": "3pNJjUIWqDtf",
    "outputId": "fcd0bb87-b4f1-423b-91f2-84e1c9a8b640"
   },
   "outputs": [],
   "source": [
    "target_path=\"Label_Training.tif\"# Path to Label\n",
    "\n",
    "# read geotiff data to numpy array\n",
    "\n",
    "with rasterio.open(target_path, 'r') as ds:\n",
    "\n",
    "    arr = ds.read() \n",
    "  \n",
    "    arr=arr.astype('uint8')\n",
    "    \n",
    "    \n",
    "    arr= tf.one_hot(\n",
    "    arr,#your image with label\n",
    "    7, #the number of classes   \n",
    "    ) \n",
    "   \n",
    "    # change the shape of input tiff for feeding models\n",
    "\n",
    "arr1 = np.swapaxes(arr, 1, 0)\n",
    "arr2_label = np.swapaxes(arr1, 1, 2)\n",
    "print(arr2_label.shape)\n",
    "\n",
    "# create smaller image patches for training\n",
    "\n",
    "patch2 = patchify.patchify(arr2_label ,(ps,ps,1,7), step=s) \n",
    "print(patch2.shape)\n",
    "\n",
    "# Out of the image patches we create a tensor: number of sample images; size; number of channels \n",
    "\n",
    "patch_Y = np.reshape(patch2,(patch2.shape[0]*patch2.shape[1],ps,ps,1*7))\n",
    "print(patch_Y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Validation and Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1271,
     "status": "ok",
     "timestamp": 1653290728253,
     "user": {
      "displayName": "Yunya Gao",
      "userId": "05443726764578958815"
     },
     "user_tz": -120
    },
    "id": "hG9XChZIqDtl",
    "outputId": "d46dfef0-679b-4fa1-b3e7-32c3fd1c9394"
   },
   "outputs": [],
   "source": [
    "#Testsplit\n",
    "\n",
    "X_tr, X_va, Y_tr, Y_va = train_test_split(patch_X, patch_Y, test_size=0.1) \n",
    "print(X_tr.shape, Y_tr.shape, X_va.shape, Y_va.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CwE6GZlaqDtd"
   },
   "source": [
    "# Prepare U-Net Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4319195,
     "status": "ok",
     "timestamp": 1653295372666,
     "user": {
      "displayName": "Yunya Gao",
      "userId": "05443726764578958815"
     },
     "user_tz": -120
    },
    "id": "2GdDhga8x-a4",
    "outputId": "d61b4f29-1389-469f-b4ec-ff2a73c540f1"
   },
   "outputs": [],
   "source": [
    "#Define Model parameter \n",
    "model_name='landcover_new.h5' # name of the model\n",
    "backbone = 'resnet34'#backbone: the libary provides different backbones- we will use resnet34\n",
    "pretrained_weights =None\n",
    "nclass = 7 # number of class found in the training image\n",
    "patchsize = ps \n",
    "nbands = 3 # number of bands of the training image\n",
    "activation_func = 'softmax' # activation function\n",
    "# define model metrics to be shown to follow the training porcess and the model performance\n",
    "metrics_list = [metrics.CategoricalAccuracy(), metrics.CategoricalCrossentropy(), metrics.MeanIoU(8),metrics.Precision(),metrics.Recall()]\n",
    "\n",
    "epochs = 200  # define training epochs\n",
    "OPT = keras.optimizers.Adam(learning_rate=0.01, decay=0.01/epochs)\n",
    "batchsize = ps# define the batchsize \n",
    "callbacks =[keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)]  # implement a callback to stop the model from training when a certain hyopthese is true\n",
    "\n",
    "# define the model\n",
    "model = Unet(backbone, \n",
    "             encoder_weights=pretrained_weights, \n",
    "             classes=nclass,\n",
    "             input_shape=(patchsize, patchsize, nbands), \n",
    "             activation=activation_func)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', metrics=metrics_list, optimizer=OPT)\n",
    "\n",
    "print(\"Starting training\")\n",
    "\n",
    "# start the model training and save the trainings run\n",
    "\n",
    "history = model.fit( x=X_tr,\n",
    "                      y=Y_tr,\n",
    "                      validation_data=(X_va, Y_va), \n",
    "                      batch_size=batchsize,\n",
    "                      epochs=epochs,\n",
    "                      verbose=2,\n",
    "                      callbacks=callbacks,\n",
    "                      shuffle=True\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1815,
     "status": "ok",
     "timestamp": 1653297738165,
     "user": {
      "displayName": "Yunya Gao",
      "userId": "05443726764578958815"
     },
     "user_tz": -120
    },
    "id": "axJt2kX0MjtG"
   },
   "outputs": [],
   "source": [
    "# save the trained model\n",
    "model.save(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GEE4DA8DqDtm"
   },
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Evaluation Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 382,
     "status": "ok",
     "timestamp": 1653303878784,
     "user": {
      "displayName": "Yunya Gao",
      "userId": "05443726764578958815"
     },
     "user_tz": -120
    },
    "id": "F4WCxUXbqDtm"
   },
   "outputs": [],
   "source": [
    "test_img=\"Image_Prediction.tif\" # Path to evaluation image\n",
    "# geotiff to array\n",
    "with rasterio.open(test_img, 'r') as ds:\n",
    "\n",
    "    arr_ti = ds.read() \n",
    " \n",
    "    \n",
    "print(arr_ti.shape)\n",
    "\n",
    "# change the shape of input tiff for feeding models\n",
    "\n",
    "arr1_ti = np.swapaxes(arr_ti, 1, 0)\n",
    "\n",
    "print(arr1_ti.shape)\n",
    "\n",
    "arr2_ti = np.swapaxes(arr1_ti, 1, 2)\n",
    "\n",
    "print(arr2_ti.shape) \n",
    "\n",
    "# Change the shape of the input evaluation data\n",
    "patchsize = ps\n",
    "nbands = 3\n",
    "# to make the shape of input image the same as label data, delete some rows and cols\n",
    "new_row, new_col = 207, 173 # rows and columns\n",
    "arr2_ti = arr2_ti[:new_row, :new_col, :]\n",
    "print(arr2_ti.shape)\n",
    "\n",
    "patch1_ti = patchify.patchify(arr2_ti, (patchsize,patchsize,nbands), step=patchsize) #1952 #3264\n",
    "num_patch_row = int(arr2_ti.shape[0]/patchsize)\n",
    "num_patch_col = int(arr2_ti.shape[1]/patchsize)\n",
    "num_total = num_patch_row * num_patch_col\n",
    "\n",
    "# Out of the image patches we create a tensor: number of sample images; size; number of channels \n",
    "\n",
    "test_img_patch = np.reshape(patch1_ti, (num_total, patchsize, patchsize, nbands)) \n",
    "\n",
    "print(test_img_patch.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Evaluation Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 524,
     "status": "ok",
     "timestamp": 1653299945446,
     "user": {
      "displayName": "Yunya Gao",
      "userId": "05443726764578958815"
     },
     "user_tz": -120
    },
    "id": "RDss78YAqDtm",
    "outputId": "7d269748-2af5-44f1-8eec-4df6b6e3cf44"
   },
   "outputs": [],
   "source": [
    "test_label=\"Label_Prediction_new_classes.tif\" # Path to evaluation labels\n",
    "with rasterio.open(test_label, 'r') as ds:\n",
    "\n",
    "    arr_tl = ds.read() \n",
    "    \n",
    "    arr_tl=arr_tl.astype('uint8')\n",
    "   \n",
    "\n",
    "    arr_tl= tf.one_hot(\n",
    "    arr_tl,#your image with label\n",
    "    7, #the number of classes   \n",
    "    )\n",
    "\n",
    "\n",
    "arr_tl = arr_tl.numpy()\n",
    "arr_tl = arr_tl[0]\n",
    "print(arr_tl.shape)\n",
    "\n",
    "\n",
    "\n",
    "patchsize = ps\n",
    "nbands = 7\n",
    "new_row, new_col = 207, 173\n",
    "arr_tl = arr_tl[:new_row, :new_col, :]\n",
    "print(arr_tl.shape)\n",
    "\n",
    "patch1_tl = patchify.patchify(arr_tl, (patchsize,patchsize,nbands), step=patchsize) \n",
    "num_patch_row = int(arr_tl.shape[0]/patchsize)\n",
    "num_patch_col = int(arr_tl.shape[1]/patchsize)\n",
    "num_total = num_patch_row * num_patch_col\n",
    "test_label_patch = np.reshape(patch1_tl, (num_total, patchsize, patchsize, nbands))\n",
    "print(test_label_patch.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Trained Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7548,
     "status": "ok",
     "timestamp": 1653300210755,
     "user": {
      "displayName": "Yunya Gao",
      "userId": "05443726764578958815"
     },
     "user_tz": -120
    },
    "id": "sjMMxMPmqDtn",
    "outputId": "7879df04-3da0-443b-c344-80ba527dd686"
   },
   "outputs": [],
   "source": [
    "weights_name = 'landcover_new.h5'\n",
    "model_pred=load_model(weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7548,
     "status": "ok",
     "timestamp": 1653300210755,
     "user": {
      "displayName": "Yunya Gao",
      "userId": "05443726764578958815"
     },
     "user_tz": -120
    },
    "id": "sjMMxMPmqDtn",
    "outputId": "7879df04-3da0-443b-c344-80ba527dd686"
   },
   "outputs": [],
   "source": [
    "#performance of model on normal prediciton data\n",
    "\n",
    "evl_test=model_pred.evaluate(test_img_patch, test_label_patch) \n",
    "\n",
    "prediction_label = model_pred.predict(test_img_patch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reconstruct Predicted Patches Into A Complete Testing Area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 469,
     "status": "ok",
     "timestamp": 1653300893120,
     "user": {
      "displayName": "Yunya Gao",
      "userId": "05443726764578958815"
     },
     "user_tz": -120
    },
    "id": "SYDaY-LKYJfu"
   },
   "outputs": [],
   "source": [
    "# reconstruct predicted patches into a complete testing area\n",
    "def reshape_prediction_by_unpatchify(prediction, patchsize, nclass, lab_array):\n",
    "    \n",
    "    num_row = int(lab_array.shape[0]/patchsize)\n",
    "    num_col = int(lab_array.shape[1]/patchsize)\n",
    "\n",
    "    prediction_reshape = prediction.reshape((num_row, num_col, 1, patchsize, patchsize, nclass))\n",
    "\n",
    "    target_shape = (num_row*patchsize, num_col*patchsize, nclass)\n",
    "\n",
    "    prediction_reshape_unpatch = unpatchify(prediction_reshape, target_shape)\n",
    "\n",
    "    return prediction_reshape_unpatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 380,
     "status": "ok",
     "timestamp": 1653300897085,
     "user": {
      "displayName": "Yunya Gao",
      "userId": "05443726764578958815"
     },
     "user_tz": -120
    },
    "id": "IHUGdRCBYgad",
    "outputId": "e189c86a-f482-44b1-e32e-9623ea535d3b"
   },
   "outputs": [],
   "source": [
    "prediction = prediction_label\n",
    "nclass = 7\n",
    "lab_array = arr_tl\n",
    "prediction_label_complete = reshape_prediction_by_unpatchify(prediction, patchsize, nclass, lab_array)\n",
    "prediction_label_complete.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reassign the values to predicted labels\n",
    "prediction_label_final=np.argmax(prediction_label_complete, axis=2)\n",
    "print(prediction_label_final.shape)\n",
    "t=tf.reduce_max(prediction_label_final)\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Prediction Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=model_pred.predict(test_img_patch)\n",
    "\n",
    "with rasterio.open(test_label, 'r') as ds:\n",
    "\n",
    "    ground_truth_ = ds.read() \n",
    "    \n",
    "    ground_truth_ = ground_truth_.astype('uint8')\n",
    "\n",
    "ground_truth = ground_truth_[0, :, :]\n",
    "\n",
    "y_pred_argmax=np.argmax(y_pred, axis=3) [0,:,:] \n",
    "print(y_pred_argmax.shape   )\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.subplot(231)\n",
    "plt.title('Testing Image')\n",
    "plt.imshow(ground_truth, cmap='gray')\n",
    "plt.subplot(232)\n",
    "plt.title('Testing Label')\n",
    "#plt.imshow(prediction_label_final[0,:,:,0], cmap='jet')\n",
    "\n",
    "plt.subplot(232)\n",
    "plt.title('Prediction on test image')\n",
    "plt.imshow(prediction_label_final, cmap='jet')\n",
    "plt.show()\n",
    "\n",
    "img=np.argmax(test_label_patch, axis=3)[0,:,:] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Prediction Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_array=img_to_array(img) \n",
    "save_img('Testing_label.tiff',img_array)\n",
    "img_pred=prediction_label_final\n",
    "save= 'Prediction.tif'\n",
    "cv2.imwrite(save,img_pred)\n",
    "print('Prediction and Testing labels saved:'+' '+save)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "UNet_normal.ipynb",
   "provenance": []
  },
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
