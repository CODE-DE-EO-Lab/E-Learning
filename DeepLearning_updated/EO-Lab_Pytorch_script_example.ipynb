{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NZ6TXg8HqDtX"
   },
   "source": [
    "# Setup: Importing Necessary Libraries\n",
    "#### Assuming libraries like torch, torchvision, torchmetrics, numpy and rasterio are installed in the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from PIL import Image, ImageEnhance\n",
    "import patchify\n",
    "from patchify import unpatchify \n",
    "import math\n",
    "import cv2\n",
    "import torch\n",
    "from skimage.io import imread        # needs installation \n",
    "import numpy as np\n",
    "import random \n",
    "import os\n",
    "import copy\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import rasterio                      \n",
    "from rasterio.plot import show\n",
    "from rasterio.merge import merge\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "from torch import nn\n",
    "from torchvision.io.image import read_image\n",
    "from torchvision.models.segmentation import deeplabv3_resnet50\n",
    "import torchmetrics\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define the patch size and steps of the training image\n",
    "ps=64 \n",
    "s=int(ps/4) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data: Import Training Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1450,
     "status": "ok",
     "timestamp": 1653290705016,
     "user": {
      "displayName": "Yunya Gao",
      "userId": "05443726764578958815"
     },
     "user_tz": -120
    },
    "id": "vpsWxucDqDtd",
    "outputId": "667344a6-35a9-4539-fe98-2783a6c93ae3",
    "tags": []
   },
   "outputs": [],
   "source": [
    "img_path=\"Image_Training.tif\"  # Path to Image\n",
    "with rasterio.open(img_path, 'r') as ds:\n",
    "    arr = ds.read() \n",
    "arr1 = np.swapaxes(arr, 1, 0)\n",
    "arr2_image = np.swapaxes(arr1, 1, 2)\n",
    "patch2 = patchify.patchify(arr2_image ,(ps,ps,3), step=s)\n",
    "patch_X = np.reshape(patch2, (patch2.shape[0]*patch2.shape[1], 3, ps,ps))\n",
    "print(f'Image shape: {patch_X.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data: Import Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 366,
     "status": "ok",
     "timestamp": 1653290707972,
     "user": {
      "displayName": "Yunya Gao",
      "userId": "05443726764578958815"
     },
     "user_tz": -120
    },
    "id": "3pNJjUIWqDtf",
    "outputId": "fcd0bb87-b4f1-423b-91f2-84e1c9a8b640",
    "tags": []
   },
   "outputs": [],
   "source": [
    "target_path=\"Label_Training.tif\"# Path to Label\n",
    "with rasterio.open(target_path, 'r') as ds:\n",
    "    arr = ds.read().squeeze() \n",
    "    arr=arr.astype('uint8')\n",
    "    labels = list(np.unique(arr))\n",
    "    labels_ = np.zeros((len(labels), arr.shape[0], arr.shape[1]), np.uint8)\n",
    "    for i in range(len(labels)):\n",
    "        x = np.where(arr==i, 1, 0)\n",
    "        labels_[i,:,:] = x\n",
    "arr2_label = labels_.reshape(651, 1169, 8)\n",
    "patch2 = patchify.patchify(arr2_label ,(ps,ps,8), step=s) \n",
    "patch_Y = np.reshape(patch2,(patch2.shape[0]*patch2.shape[1],8, ps,ps))\n",
    "print(patch_Y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data: Array partitioning for train test sample chips\n",
    "###### custom function is required to partition array or samples in pytorch environemnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1271,
     "status": "ok",
     "timestamp": 1653290728253,
     "user": {
      "displayName": "Yunya Gao",
      "userId": "05443726764578958815"
     },
     "user_tz": -120
    },
    "id": "hG9XChZIqDtl",
    "outputId": "d46dfef0-679b-4fa1-b3e7-32c3fd1c9394",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def trainTesitsplit(x, y, ratio=0.1): # follows systematic random sampling\n",
    "    x = torch.from_numpy(x.astype(float))\n",
    "    y = torch.from_numpy(y.astype(float))\n",
    "    \n",
    "    N = x.shape[0]\n",
    "    n = int(ratio*N)\n",
    "    step = int(N/n)\n",
    "    full = list(range(x.shape[0]))\n",
    "    v_ind = list(range(0, N, step))\n",
    "    t_ind = list(set(full).symmetric_difference(set(v_ind)))\n",
    "    \n",
    "    vv_x = torch.index_select(x, 0, torch.tensor(v_ind, dtype=torch.long))\n",
    "    tt_x = torch.index_select(x, 0, torch.tensor(t_ind, dtype=torch.long))\n",
    "    \n",
    "    vv_y = torch.index_select(y, 0, torch.tensor(v_ind, dtype=torch.long))\n",
    "    tt_y = torch.index_select(y, 0, torch.tensor(t_ind, dtype=torch.long))\n",
    "    \n",
    "    return tt_x, tt_y, vv_x, vv_y "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Data: Prepare pytorch data loader\n",
    "for smooth training, data flow and memory usage, pytorch has dataset and dataloader class which is designed to be customized as our data structure and training procedure, example below is thecustomdataset class amended to take data from image and labels of which are torch tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CustomImageDataset(Dataset): \n",
    "    def __init__(self, arr_, lbl_, tensify=False):\n",
    "        self.tensify = tensify\n",
    "        self.arr_ = arr_\n",
    "        self.lbl_ = lbl_\n",
    "        self.tarsform = transforms.Compose([transforms.ToTensor(),\n",
    "                                            transforms.Lambda(lambda img: img.float())\n",
    "                                           ])\n",
    "    def __len__(self):\n",
    "        return len(self.arr_)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        image = self.arr_[idx]\n",
    "        label = self.lbl_[idx]\n",
    "        if not self.tensify:\n",
    "            return image, label\n",
    "        else:\n",
    "            return self.tarsform(image), self.tarsform(label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CwE6GZlaqDtd"
   },
   "source": [
    "# Model: Prepare FCN_ResNet Model\n",
    "###### see https://pytorch.org/vision/0.11/models.html for further notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def define_model(bakbone_depth=50, all_weight=None, num_class=8, phase='train'):\n",
    "    if bakbone_depth == 50:\n",
    "        model = deeplabv3_resnet50(num_classes=num_class, aux_loss=False)\n",
    "    elif bakbone_depth == 101:\n",
    "        model = deeplabv3_resnet101(num_classes=num_class, aux_loss=False)\n",
    "    else:\n",
    "        raise ValueError('Depth for resnet not known')\n",
    "    if phase == 'train':\n",
    "        model.train()\n",
    "    else:\n",
    "        model.eval()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Specify model phyper arameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "bakbone_depth=101\n",
    "all_weight=None \n",
    "num_class=8 # including bacground\n",
    "phase='train'\n",
    "bach_size = 20\n",
    "epochs = 50\n",
    "lr_rate = 0.0001\n",
    "device = device =  torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# define and load model using parameters\n",
    "\n",
    "model = define_model(bakbone_depth=bakbone_depth,\n",
    "                     all_weight=all_weight,\n",
    "                     num_class=num_class,\n",
    "                     phase=phase)\n",
    "\n",
    "model = model.to(device)  # put the model either on CPU or GPU depending on availability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### Torch training process is not the same as keras where tensorflow is built on top of as a wrap module, in pytorch we shoud define everything explicitly or use a pytorch wraper pytorch lightening as alternative wich can be found here https://lightning.ai/pages/open-source/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4319195,
     "status": "ok",
     "timestamp": 1653295372666,
     "user": {
      "displayName": "Yunya Gao",
      "userId": "05443726764578958815"
     },
     "user_tz": -120
    },
    "id": "2GdDhga8x-a4",
    "outputId": "d61b4f29-1389-469f-b4ec-ff2a73c540f1",
    "tags": []
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(), lr_rate)  # optimizer \n",
    "activation = torch.nn.Softmax(dim=1).to(device)\n",
    "acc_fn = torchmetrics.Accuracy(task='multiclass', num_classes=8, average='weighted', mdmc_reduce='samplewise').to(device)\n",
    "ls_fn = nn.CrossEntropyLoss().to(device)\n",
    "# define data set and loader for training\n",
    "x_train, y_train, x_vaid, y_valid = trainTesitsplit(patch_X, patch_Y,ratio=0.1)  # sample array\n",
    "train_dataset = CustomImageDataset(arr_ = x_train, lbl_ = y_train) # put in custom dataset\n",
    "valid_dataset = CustomImageDataset(arr_ = x_vaid, lbl_ = y_valid)  # put in custom datset\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=bach_size, drop_last=True, shuffle=True)\n",
    "valid_loader = DataLoader(dataset = valid_dataset, batch_size=bach_size, drop_last=True, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Categorical cross entrophy loss as alternative loss function as there is no direct implementation in pytorch alternative solution is using torch CrossEntropy function on logits and undertake softmax during inerence "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def loss_fn(ref, pred): \n",
    "    x = torch.mean(-torch.sum(ref*torch.log(pred), dim=(1,2)))\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "save_dir = 'weight'\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    \n",
    "VL = {'loss':[], 'acc':[]}\n",
    "TA = {'loss':[], 'acc':[]}\n",
    "\n",
    "best_weight = None\n",
    "\n",
    "for epoch in range(1, epochs+1):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    control = 0\n",
    "    for j, (X, Y) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        X = X.float().to(device)\n",
    "        Y = Y.to(device) \n",
    "        logits = model(X)\n",
    "        softs = activation(logits['out'])\n",
    "        loss = ls_fn(logits['out'], Y)\n",
    "        # loss = loss_fn(Y, softs)\n",
    "        acc = acc_fn(torch.argmax(softs, dim=1), torch.argmax(Y, dim=1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        with torch.no_grad():\n",
    "            epoch_loss+=loss.item()\n",
    "            epoch_acc+=acc.item()\n",
    "            print(f'step: {j}, step_loss: {loss.item()}, step_acc: {acc.item()}', end = '\\r', flush=True)\n",
    "        control+=1\n",
    "\n",
    "        with torch.no_grad():\n",
    "            epoch_loss = epoch_loss / control\n",
    "            TA['loss'].append(epoch_loss)\n",
    "            TA['acc'].append(epoch_acc/control)\n",
    "            print(f'+++ {epoch}: step: {j}, train_loss: {epoch_loss}, train_acc:{epoch_acc/control} +++',  end = '\\r', flush=True)\n",
    "\n",
    "    # validate the model\n",
    "    val_loss = 0\n",
    "    val_acc = 0\n",
    "    control = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for image, target in valid_loader:\n",
    "            image, target = image.float().to(device), target.to(device) # target.float().to(self.device)\n",
    "            output = model(image)\n",
    "            softs = activation(output['out'])\n",
    "            # vloss = loss_fn(softs, target)\n",
    "            vloss = ls_fn(output['out'], target)\n",
    "            vacc = acc_fn(torch.argmax(softs,dim=1), torch.argmax(target, dim=1))\n",
    "            val_loss += vloss.item()\n",
    "            val_acc+=vacc.item()\n",
    "            control+=1\n",
    "        val_loss = val_loss/control\n",
    "        val_acc = val_acc/control\n",
    "        VL['loss'].append(val_loss)\n",
    "        VL['acc'].append(val_acc)\n",
    "        print(f'+++ {epoch}: step: {j}, valid_loss: {val_loss}, valid_acc: {val_acc}')\n",
    "\n",
    "        if epoch == 1:\n",
    "            best_valid = VL[\"loss\"][-1]\n",
    "            best_weight = copy.deepcopy(model.state_dict())\n",
    "        else:\n",
    "            if VL[\"loss\"][-1]<=best_valid:\n",
    "                best_valid = VL[\"loss\"][-1]\n",
    "                best_weight = copy.deepcopy(model.state_dict())\n",
    "            else:\n",
    "                pass\n",
    "\n",
    "name = save_dir + '/checkpoint.pth'   # self.weigth_path\n",
    "torch.save(best_weight, name)\n",
    "\n",
    "plt.plot(TA['loss'], label='training loss')\n",
    "plt.plot(VL['loss'], label = 'validation loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('epochs')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(TA['acc'], label='Taining accuracy')\n",
    "plt.plot(VL['acc'], label = 'Validation accuracy')\n",
    "plt.ylabel('Accuarcy')\n",
    "plt.xlabel('epochs')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GEE4DA8DqDtm"
   },
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Evaluation Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "executionInfo": {
     "elapsed": 382,
     "status": "ok",
     "timestamp": 1653303878784,
     "user": {
      "displayName": "Yunya Gao",
      "userId": "05443726764578958815"
     },
     "user_tz": -120
    },
    "id": "F4WCxUXbqDtm",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(207, 173, 3)\n",
      "torch.Size([6, 3, 64, 64])\n"
     ]
    }
   ],
   "source": [
    "test_img=\"Image_Prediction.tif\" \n",
    "with rasterio.open(test_img, 'r') as ds:\n",
    "    arr_ti = ds.read() \n",
    "shape = arr_ti.squeeze().shape\n",
    "arr2_ti = arr_ti.reshape(shape[1], shape[2], shape[0])\n",
    "\n",
    "patchsize = ps\n",
    "nbands = 3\n",
    "new_row, new_col = 207, 173 \n",
    "arr2_ti = arr2_ti[:new_row, :new_col, :]\n",
    "print(arr2_ti.shape)\n",
    "\n",
    "patch1_ti = patchify.patchify(arr2_ti, (patchsize,patchsize,nbands), step=patchsize) #1952 #3264\n",
    "num_patch_row = int(arr2_ti.shape[0]/patchsize)\n",
    "num_patch_col = int(arr2_ti.shape[1]/patchsize)\n",
    "num_total = num_patch_row * num_patch_col\n",
    "test_img_patch = np.reshape(patch1_ti, (num_total, nbands, patchsize, patchsize))\n",
    "test_img_patch = torch.from_numpy(test_img_patch.astype(float))\n",
    "print(test_img_patch.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Evaluation Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 524,
     "status": "ok",
     "timestamp": 1653299945446,
     "user": {
      "displayName": "Yunya Gao",
      "userId": "05443726764578958815"
     },
     "user_tz": -120
    },
    "id": "RDss78YAqDtm",
    "outputId": "7d269748-2af5-44f1-8eec-4df6b6e3cf44",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(207, 173, 8)\n",
      "torch.Size([6, 8, 64, 64])\n"
     ]
    }
   ],
   "source": [
    "test_label=\"Label_Prediction_new_classes.tif\" # Path to evaluation labels\n",
    "with rasterio.open(test_label, 'r') as ds:\n",
    "    arr_tl = ds.read() \n",
    "    arr_tl=arr_tl.astype('uint8').squeeze()\n",
    "    \n",
    "    labels = list(np.unique(arr_tl))\n",
    "    labels_ = np.zeros((len(labels), arr_tl.shape[0], arr_tl.shape[1]), np.uint8)\n",
    "    for i in range(len(labels)):\n",
    "        x = np.where(arr_tl==i, 1, 0)\n",
    "        labels_[i,:,:] = x\n",
    "        \n",
    "lb_shape = labels_.shape\n",
    "arr_tl = labels_.reshape(lb_shape[1], lb_shape[2], lb_shape[0])\n",
    "\n",
    "patchsize = ps\n",
    "nbands = 8\n",
    "new_row, new_col = 207, 173\n",
    "arr_tl = arr_tl[:new_row, :new_col, :]\n",
    "print(arr_tl.shape)\n",
    "\n",
    "patch1_tl = patchify.patchify(arr_tl, (patchsize,patchsize,nbands), step=patchsize) \n",
    "num_patch_row = int(arr_tl.shape[0]/patchsize)\n",
    "num_patch_col = int(arr_tl.shape[1]/patchsize)\n",
    "num_total = num_patch_row * num_patch_col\n",
    "test_label_patch = np.reshape(patch1_tl, (num_total, nbands, patchsize, patchsize))\n",
    "test_label_patch = torch.from_numpy(test_label_patch.astype(float))\n",
    "# print(test_label_patch.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Trained Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7548,
     "status": "ok",
     "timestamp": 1653300210755,
     "user": {
      "displayName": "Yunya Gao",
      "userId": "05443726764578958815"
     },
     "user_tz": -120
    },
    "id": "sjMMxMPmqDtn",
    "outputId": "7879df04-3da0-443b-c344-80ba527dd686",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights_name = save_dir + '/checkpoint.pth'\n",
    "\n",
    "model_pred = define_model(bakbone_depth=bakbone_depth,\n",
    "                     all_weight=all_weight,\n",
    "                     num_class=num_class,\n",
    "                     phase='test')\n",
    "model_pred = model.to(device)\n",
    "model_pred.load_state_dict(torch.load(weights_name))   # learned weightes loaded using model builtin function \"load_state_dict\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7548,
     "status": "ok",
     "timestamp": 1653300210755,
     "user": {
      "displayName": "Yunya Gao",
      "userId": "05443726764578958815"
     },
     "user_tz": -120
    },
    "id": "sjMMxMPmqDtn",
    "outputId": "7879df04-3da0-443b-c344-80ba527dd686",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0304, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "#performance of model on normal prediciton data\n",
    "test_img_patch = test_img_patch.to(device)\n",
    "test_label_patch = test_label_patch.to(device)\n",
    "logs = model_pred(test_img_patch.float())\n",
    "softs = torch.softmax(logs['out'], dim=1)\n",
    "accuracy = acc_fn(torch.argmax(softs, dim=1),torch.argmax(test_label_patch, axis=1))\n",
    "# print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reconstruct Predicted Patches Into A Complete Testing Area [Optitional]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "executionInfo": {
     "elapsed": 469,
     "status": "ok",
     "timestamp": 1653300893120,
     "user": {
      "displayName": "Yunya Gao",
      "userId": "05443726764578958815"
     },
     "user_tz": -120
    },
    "id": "SYDaY-LKYJfu",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# reconstruct predicted patches into a complete testing area\n",
    "def reshape_prediction_by_unpatchify(prediction, patchsize, nclass, lab_array):\n",
    "    num_row = int(lab_array.shape[0]/patchsize)\n",
    "    num_col = int(lab_array.shape[1]/patchsize)\n",
    "    prediction_reshape = prediction.reshape((num_row, num_col, 1, patchsize, patchsize, nclass))\n",
    "    target_shape = (num_row*patchsize, num_col*patchsize, nclass)\n",
    "    prediction_reshape_unpatch = unpatchify(prediction_reshape, target_shape)\n",
    "    # please note that unpatchify is not giving perfect spatial tiles, it gives blocky images.\n",
    "    # the usage here is just to demonstrate the workflow and we do not recommend for final product version\n",
    "    return prediction_reshape_unpatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 380,
     "status": "ok",
     "timestamp": 1653300897085,
     "user": {
      "displayName": "Yunya Gao",
      "userId": "05443726764578958815"
     },
     "user_tz": -120
    },
    "id": "IHUGdRCBYgad",
    "outputId": "e189c86a-f482-44b1-e32e-9623ea535d3b",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(207, 173, 8) (192, 128, 8) (207, 173, 3)\n"
     ]
    }
   ],
   "source": [
    "prediction = softs.permute(0, 2, 3, 1).cpu().detach().numpy()\n",
    "nclass = 8\n",
    "lab_array = arr_tl\n",
    "prediction_label_complete = reshape_prediction_by_unpatchify(prediction, patchsize, nclass, lab_array)\n",
    "print(arr_tl.shape, prediction_label_complete.shape, arr2_ti.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Prediction Results [Optional]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,3, figsize=(10, 15), sharex=True, sharey=True)\n",
    "ax[0].imshow(arr2_ti)\n",
    "ax[0].set_title('Testing Image')\n",
    "ax[1].imshow(np.argmax(arr_tl, axis=-1))\n",
    "ax[0].set_title('Testing Label')\n",
    "ax[2].imshow(np.argmax(prediction_label_complete, axis=-1))\n",
    "ax[0].set_title('Prediction on test image')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Prediction Results [Optional]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction and Testing labels saved: Prediction.tif\n"
     ]
    }
   ],
   "source": [
    "img_pred=np.argmax(prediction_label_complete, axis=-1)\n",
    "save= 'Prediction.tif'\n",
    "cv2.imwrite(save, img_pred)\n",
    "print('Prediction and Testing labels saved:'+' '+save)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "UNet_normal.ipynb",
   "provenance": []
  },
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
